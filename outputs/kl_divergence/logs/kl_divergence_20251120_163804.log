[16:38:04] ================================================================================
[16:38:04] KL DIVERGENCE ANALYSIS PIPELINE
[16:38:04] ================================================================================
[16:38:04] Start time: 2025-11-20 16:38:04

[16:38:04] 
================================================================================
[16:38:04] LOADING DATA
[16:38:04] ================================================================================
[16:38:04] Loading metadata...
[16:38:04]   Total sentences: 33522
[16:38:04] 
Loading base activations...
[16:38:04]   Layer 8: (33522, 1536)
[16:38:04]   Layer 16: (33522, 1536)
[16:38:05]   Layer 24: (33522, 1536)
[16:38:05]   Layer 28: (33522, 1536)
[16:38:05] 
Loading instruct activations...
[16:38:05]   Layer 8: (33522, 1536)
[16:38:05]   Layer 16: (33522, 1536)
[16:38:05]   Layer 24: (33522, 1536)
[16:38:05]   Layer 28: (33522, 1536)
[16:38:05] 
Inferring question types from sentences...
[16:38:05] 
Data loading complete!
[16:38:05]   Groups: ['suppression' 'enhancement' 'control']
[16:38:05]   Attributes: 16
[16:38:05]   States: 36
[16:38:05]   Question types: 4
[16:38:05] 
================================================================================
[16:38:05] OVERALL KL DIVERGENCE ANALYSIS
[16:38:05] ================================================================================
[16:38:05] 
Layer 8...
[16:38:13]   KL divergence: 112.608162
[16:38:13]   JS divergence: 112.261092
[16:38:13] 
Layer 16...
[16:38:21]   KL divergence: 106.843684
[16:38:21]   JS divergence: 109.848301
[16:38:21] 
Layer 24...
[16:38:30]   KL divergence: 115.477380
[16:38:30]   JS divergence: 115.125183
[16:38:30] 
Layer 28...
[16:38:37]   KL divergence: 335.037061
[16:38:37]   JS divergence: 365.140832
[16:38:37] 
Generating overall KL divergence plot...
[16:38:38]   Saved: overall_kl_divergence.png
[16:38:38] 
================================================================================
[16:38:38] GROUP-LEVEL KL DIVERGENCE ANALYSIS
[16:38:38] ================================================================================
[16:38:38] 
SUPPRESSION GROUP:
[16:38:38]   Samples: 11934
[16:38:44]   Layer 8 - KL: 122.309506
[16:38:50]   Layer 16 - KL: 113.575130
[16:38:57]   Layer 24 - KL: 124.244716
[16:39:02]   Layer 28 - KL: 345.849519
[16:39:02] 
ENHANCEMENT GROUP:
[16:39:02]   Samples: 11970
[16:39:08]   Layer 8 - KL: 120.485814
[16:39:14]   Layer 16 - KL: 112.558098
[16:39:19]   Layer 24 - KL: 122.907792
[16:39:25]   Layer 28 - KL: 343.985809
[16:39:25] 
CONTROL GROUP:
[16:39:25]   Samples: 9618
[16:39:30]   Layer 8 - KL: 136.254930
[16:39:36]   Layer 16 - KL: 121.522501
[16:39:41]   Layer 24 - KL: 136.777255
[16:39:48]   Layer 28 - KL: 379.923255
[16:39:48] 
Generating group-level KL divergence plots...
[16:39:48]   Saved: group_kl_divergence.png
[16:39:48] 
================================================================================
[16:39:48] ATTRIBUTE-LEVEL KL DIVERGENCE ANALYSIS
[16:39:48] ================================================================================
[16:44:06] Completed 16 attributes
[16:44:06] 
Generating attribute-level KL divergence heatmap...
[16:44:07]   Saved: attribute_kl_heatmap.png
[16:44:07]   Saved: top_attributes_by_layer.png
[16:44:07] 
================================================================================
[16:44:07] STATE-LEVEL KL DIVERGENCE ANALYSIS
[16:44:07] ================================================================================
[16:52:12] Completed 36 states
[16:52:12] 
Generating state-level KL divergence heatmap...
[16:52:13]   Saved: state_kl_heatmap.png
[16:52:13]   Saved: top_states_layer24.png
[16:52:13] 
================================================================================
[16:52:13] QUESTION-TYPE-LEVEL KL DIVERGENCE ANALYSIS
[16:52:13] ================================================================================
[16:52:13] 
CULTURAL_PRACTICE:
[16:52:13]   Samples: 14739
[16:52:19]   Layer 8 - KL: 128.059166
[16:52:26]   Layer 16 - KL: 120.496311
[16:52:31]   Layer 24 - KL: 133.211157
[16:52:38]   Layer 28 - KL: 359.877418
[16:52:38] 
FESTIVAL:
[16:52:38]   Samples: 3440
[16:52:44]   Layer 8 - KL: 170.662350
[16:52:50]   Layer 16 - KL: 146.635329
[16:52:55]   Layer 24 - KL: 159.645293
[16:53:00]   Layer 28 - KL: 438.449067
[16:53:00] 
GENERAL:
[16:53:00]   Samples: 15204
[16:53:07]   Layer 8 - KL: 116.316704
[16:53:15]   Layer 16 - KL: 108.521808
[16:53:20]   Layer 24 - KL: 117.520272
[16:53:26]   Layer 28 - KL: 331.658956
[16:53:26] 
KNOWN_FOR:
[16:53:26]   Samples: 139
[16:53:30]   Layer 8 - KL: 79.141882
[16:53:33]   Layer 16 - KL: 94.502955
[16:53:36]   Layer 24 - KL: 75.322199
[16:53:39]   Layer 28 - KL: 183.302038
[16:53:39] 
Generating question-type-level KL divergence plot...
[16:53:39]   Saved: question_type_kl_divergence.png
[16:53:39] 
================================================================================
[16:53:39] SUMMARY STATISTICS
[16:53:39] ================================================================================
[16:53:39] 
Overall KL Divergence by Layer:
[16:53:39]   Layer 8: 112.608162
[16:53:39]   Layer 16: 106.843684
[16:53:39]   Layer 24: 115.477380
[16:53:39]   Layer 28: 335.037061
[16:53:39] 
Group-Level KL Divergence at Layer 24:
[16:53:39]   Suppression: 124.244716
[16:53:39]   Enhancement: 122.907792
[16:53:39]   Control: 136.777255
[16:53:39] 
Maximum KL increase for suppression group: Layer 28
[16:53:39] 
================================================================================
[16:53:39] PIPELINE COMPLETE
[16:53:39] ================================================================================
[16:53:39] End time: 2025-11-20 16:53:39
[16:53:39] 
Results saved to:
[16:53:39]   Light outputs: /home/anshulk/cultural-alignment-study/outputs/kl_divergence
[16:53:39]   Heavy data: /data/user_data/anshulk/cultural-alignment-study/kl_divergence
